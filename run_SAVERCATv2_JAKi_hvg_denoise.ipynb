{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Savercat with highly vairiable genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Packages\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, BatchNormalization, LeakyReLU, Lambda\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, scale\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name = os.path.basename(os.getcwd())\n",
    "print(base_name)\n",
    "print(sc.__version__)\n",
    "sc.settings.verbosity = 3  \n",
    "sc.logging.print_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import utils functions in utils.py\n",
    "from utils import *\n",
    "# import network buiding functions in network.py\n",
    "from network import * \n",
    "# import cross_validation function in train.py\n",
    "from train import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad('../share/data/adata_subsample_hvg.h5ad')\n",
    "print(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Savercat preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_key = 'Cycle' # the name of the cell-level label to be predicted\n",
    "batch_key = 'patient' # the name of the cell-level label to be adjusted for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# savercat preprocessing step\n",
    "adata = savercat_preprocess(adata, predict_key=predict_key, adjust_key=batch_key, scaleB=True)\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if train on highly variable genes, then keep enc=(256, 256, 128), dec=(128, 256, 256)\n",
    "# leave all the parameters unchanged\n",
    "SAVER_net = CVAE(x_input_size = adata.n_vars, # number of genes\n",
    "                 b_input_size = adata.obsm['saver_batch'].shape[1], # number of batches including lib-size\n",
    "                 lb_input_size = adata.obsm['saver_targetL'].shape[1], # number of labels to predict\n",
    "                 enc = (256, 256, 128), # dim of the encoder\n",
    "                 dec = (128, 256, 256), # dim of the decoder\n",
    "                 latent_k = 30) # dimension of the low-dimensional latent space\n",
    "SAVER_net.build()\n",
    "SAVER_net.compile_model(pred_weight=1, kl_weight=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need to modify this block\n",
    "# label guided initialization step\n",
    "loss = SAVER_net.model_initialize(adata, fit_verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the directory where you want to save the file\n",
    "# 'weights_step1.h5' is the file name\n",
    "SAVER_net.model.save_weights('weights_init.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if train on highly variable genes, then keep enc=(256, 256, 128), dec=(128, 256, 256)\n",
    "# leave all the parameters unchanged\n",
    "# same as block 8 but use the weight you just saved\n",
    "SAVER_net = CVAE(x_input_size = adata.n_vars,\n",
    "                 b_input_size = adata.obsm['saver_batch'].shape[1],\n",
    "                 lb_input_size = adata.obsm['saver_targetL'].shape[1],\n",
    "                 enc = (256, 256, 128),\n",
    "                 dec = (128, 256, 256),\n",
    "                 latent_k = 30)\n",
    "SAVER_net.build()\n",
    "SAVER_net.load_weights('weights_init.h5') # fill in the weight file you just saved\n",
    "SAVER_net.compile_model(pred_weight=0., kl_weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# no need to modify this block\n",
    "# train savercat model which do the dimension reduction\n",
    "loss = SAVER_net.model_finetune(adata, fit_verbose=1)\n",
    "SAVER_net.model.save_weights('weights_ft.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the low-dimensional embedding for all the cells, and save to a csv file\n",
    "meta_df_train = adata.obs\n",
    "z_train = SAVER_net.extra_models['mean_out'].predict([adata.X, adata.obsm['saver_batch']])\n",
    "z_df = pd.DataFrame(z_train, \n",
    "                    index = meta_df_train.index,\n",
    "                    columns = ['saver{}'.format(i+1) for i in range(SAVER_net.latent_k)])\n",
    "z_df.to_csv('lowdim_savercat_hvg.csv') # where you want to save the low-dimensional embeddings learned by SAVERCAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cross validation step is necessary for the next denoising step.\n",
    "# This step may take several hours to run.\n",
    "SAVER_net = CVAE(x_input_size = adata.n_vars,\n",
    "                 b_input_size = adata.obsm['saver_batch'].shape[1],\n",
    "                 lb_input_size = adata.obsm['saver_targetL'].shape[1],\n",
    "                 enc = (256, 256, 128),\n",
    "                 dec = (128, 256, 256),\n",
    "                 latent_k = 30)\n",
    "train_cv(adata, SAVER_net, weights_orig_filename='weights_init.h5',\n",
    "         cv_genes_file_name = 'cv_genes_idx.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.Shrinkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the network trained in step 5(fine-tune the model), to predict gene expression\n",
    "# and perform denoising. The denoised expression is saved to denoise_only_path.\n",
    "SAVER_net = CVAE(x_input_size = adata.n_vars,\n",
    "                 b_input_size = adata.obsm['saver_batch'].shape[1],\n",
    "                 lb_input_size = adata.obsm['saver_targetL'].shape[1],\n",
    "                 enc = (256, 256, 128),\n",
    "                 dec = (128, 256, 256),\n",
    "                 latent_k = 30)\n",
    "\n",
    "SAVER_net.build()  \n",
    "SAVER_net.load_weights('weights_ft.h5') # weights saved in step 5(fine-tune the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_denoise_df = shrinkage(SAVER_net, adata, cv_genes_file_name='cv_genes_idx.csv',\n",
    "                         denoise_only_path = 'Saver_denoiseonly_mat.csv')\n",
    "# denoised count matrix is saved to denoise_only_path, and is returned as X_denoise_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
